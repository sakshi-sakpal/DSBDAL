Microsoft Windows [Version 10.0.19045.5737]
(c) Microsoft Corporation. All rights reserved.

C:\WINDOWS\system32>cd/

C:\>cd hadoop

C:\hadoop>hadoop namenode -format
DEPRECATED: Use of this script to execute hdfs command is deprecated.
Instead use the hdfs command for it.
2025-04-23 15:46:01,708 INFO namenode.NameNode: STARTUP_MSG:
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = DSBDA01/192.168.160.107
STARTUP_MSG:   args = [-format]
STARTUP_MSG:   version = 3.2.4
STARTUP_MSG:   classpath = C:\hadoop\etc\hadoop;C:\hadoop\share\hadoop\common;C:\hadoop\share\hadoop\common\lib\accessors-smart-2.4.7.jar;C:\hadoop\share\hadoop\common\lib\animal-sniffer-annotations-1.17.jar;C:\hadoop\share\hadoop\common\lib\asm-5.0.4.jar;C:\hadoop\share\hadoop\common\lib\audience-annotations-0.5.0.jar;C:\hadoop\share\hadoop\common\lib\avro-1.7.7.jar;C:\hadoop\share\hadoop\common\lib\checker-qual-2.5.2.jar;C:\hadoop\share\hadoop\common\lib\commons-beanutils-1.9.4.jar;C:\hadoop\share\hadoop\common\lib\commons-cli-1.2.jar;C:\hadoop\share\hadoop\common\lib\commons-codec-1.11.jar;C:\hadoop\share\hadoop\common\lib\commons-collections-3.2.2.jar;C:\hadoop\share\hadoop\common\lib\commons-compress-1.21.jar;C:\hadoop\share\hadoop\common\lib\commons-configuration2-2.1.1.jar;C:\hadoop\share\hadoop\common\lib\commons-io-2.8.0.jar;C:\hadoop\share\hadoop\common\lib\commons-lang3-3.7.jar;C:\hadoop\share\hadoop\common\lib\commons-logging-1.1.3.jar;C:\hadoop\share\hadoop\common\lib\commons-math3-3.1.1.jar;C:\hadoop\share\hadoop\common\lib\commons-net-3.6.jar;C:\hadoop\share\hadoop\common\lib\commons-text-1.4.jar;C:\hadoop\share\hadoop\common\lib\curator-client-2.13.0.jar;C:\hadoop\share\hadoop\common\lib\curator-framework-2.13.0.jar;C:\hadoop\share\hadoop\common\lib\curator-recipes-2.13.0.jar;C:\hadoop\share\hadoop\common\lib\dnsjava-2.1.7.jar;C:\hadoop\share\hadoop\common\lib\error_prone_annotations-2.2.0.jar;C:\hadoop\share\hadoop\common\lib\failureaccess-1.0.jar;C:\hadoop\share\hadoop\common\lib\gson-2.9.0.jar;C:\hadoop\share\hadoop\common\lib\guava-27.0-jre.jar;C:\hadoop\share\hadoop\common\lib\hadoop-annotations-3.2.4.jar;C:\hadoop\share\hadoop\common\lib\hadoop-auth-3.2.4.jar;C:\hadoop\share\hadoop\common\lib\htrace-core4-4.1.0-incubating.jar;C:\hadoop\share\hadoop\common\lib\httpclient-4.5.13.jar;C:\hadoop\share\hadoop\common\lib\httpcore-4.4.13.jar;C:\hadoop\share\hadoop\common\lib\j2objc-annotations-1.1.jar;C:\hadoop\share\hadoop\common\lib\jackson-annotations-2.10.5.jar;C:\hadoop\share\hadoop\common\lib\jackson-core-2.10.5.jar;C:\hadoop\share\hadoop\common\lib\jackson-core-asl-1.9.13.jar;C:\hadoop\share\hadoop\common\lib\jackson-databind-2.10.5.1.jar;C:\hadoop\share\hadoop\common\lib\jackson-jaxrs-1.9.13.jar;C:\hadoop\share\hadoop\common\lib\jackson-mapper-asl-1.9.13.jar;C:\hadoop\share\hadoop\common\lib\jackson-xc-1.9.13.jar;C:\hadoop\share\hadoop\common\lib\javax.activation-api-1.2.0.jar;C:\hadoop\share\hadoop\common\lib\javax.servlet-api-3.1.0.jar;C:\hadoop\share\hadoop\common\lib\jaxb-api-2.2.11.jar;C:\hadoop\share\hadoop\common\lib\jaxb-impl-2.2.3-1.jar;C:\hadoop\share\hadoop\common\lib\jcip-annotations-1.0-1.jar;C:\hadoop\share\hadoop\common\lib\jersey-core-1.19.jar;C:\hadoop\share\hadoop\common\lib\jersey-json-1.19.jar;C:\hadoop\share\hadoop\common\lib\jersey-server-1.19.jar;C:\hadoop\share\hadoop\common\lib\jersey-servlet-1.19.jar;C:\hadoop\share\hadoop\common\lib\jettison-1.1.jar;C:\hadoop\share\hadoop\common\lib\jetty-http-9.4.43.v20210629.jar;C:\hadoop\share\hadoop\common\lib\jetty-io-9.4.43.v20210629.jar;C:\hadoop\share\hadoop\common\lib\jetty-security-9.4.43.v20210629.jar;C:\hadoop\share\hadoop\common\lib\jetty-server-9.4.43.v20210629.jar;C:\hadoop\share\hadoop\common\lib\jetty-servlet-9.4.43.v20210629.jar;C:\hadoop\share\hadoop\common\lib\jetty-util-9.4.43.v20210629.jar;C:\hadoop\share\hadoop\common\lib\jetty-util-ajax-9.4.43.v20210629.jar;C:\hadoop\share\hadoop\common\lib\jetty-webapp-9.4.43.v20210629.jar;C:\hadoop\share\hadoop\common\lib\jetty-xml-9.4.43.v20210629.jar;C:\hadoop\share\hadoop\common\lib\jsch-0.1.55.jar;C:\hadoop\share\hadoop\common\lib\json-smart-2.4.7.jar;C:\hadoop\share\hadoop\common\lib\jsp-api-2.1.jar;C:\hadoop\share\hadoop\common\lib\jsr305-3.0.2.jar;C:\hadoop\share\hadoop\common\lib\jsr311-api-1.1.1.jar;C:\hadoop\share\hadoop\common\lib\jul-to-slf4j-1.7.35.jar;C:\hadoop\share\hadoop\common\lib\kerb-admin-1.0.1.jar;C:\hadoop\share\hadoop\common\lib\kerb-client-1.0.1.jar;C:\hadoop\share\hadoop\common\lib\kerb-common-1.0.1.jar;C:\hadoop\share\hadoop\common\lib\kerb-core-1.0.1.jar;C:\hadoop\share\hadoop\common\lib\kerb-crypto-1.0.1.jar;C:\hadoop\share\hadoop\common\lib\kerb-identity-1.0.1.jar;C:\hadoop\share\hadoop\common\lib\kerb-server-1.0.1.jar;C:\hadoop\share\hadoop\common\lib\kerb-simplekdc-1.0.1.jar;C:\hadoop\share\hadoop\common\lib\kerb-util-1.0.1.jar;C:\hadoop\share\hadoop\common\lib\kerby-asn1-1.0.1.jar;C:\hadoop\share\hadoop\common\lib\kerby-config-1.0.1.jar;C:\hadoop\share\hadoop\common\lib\kerby-pkix-1.0.1.jar;C:\hadoop\share\hadoop\common\lib\kerby-util-1.0.1.jar;C:\hadoop\share\hadoop\common\lib\kerby-xdr-1.0.1.jar;C:\hadoop\share\hadoop\common\lib\listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar;C:\hadoop\share\hadoop\common\lib\metrics-core-3.2.4.jar;C:\hadoop\share\hadoop\common\lib\netty-3.10.6.Final.jar;C:\hadoop\share\hadoop\common\lib\nimbus-jose-jwt-9.8.1.jar;C:\hadoop\share\hadoop\common\lib\paranamer-2.3.jar;C:\hadoop\share\hadoop\common\lib\protobuf-java-2.5.0.jar;C:\hadoop\share\hadoop\common\lib\re2j-1.1.jar;C:\hadoop\share\hadoop\common\lib\reload4j-1.2.18.3.jar;C:\hadoop\share\hadoop\common\lib\slf4j-api-1.7.35.jar;C:\hadoop\share\hadoop\common\lib\slf4j-reload4j-1.7.35.jar;C:\hadoop\share\hadoop\common\lib\snappy-java-1.0.5.jar;C:\hadoop\share\hadoop\common\lib\spotbugs-annotations-3.1.9.jar;C:\hadoop\share\hadoop\common\lib\stax2-api-4.2.1.jar;C:\hadoop\share\hadoop\common\lib\token-provider-1.0.1.jar;C:\hadoop\share\hadoop\common\lib\woodstox-core-5.3.0.jar;C:\hadoop\share\hadoop\common\lib\zookeeper-3.4.14.jar;C:\hadoop\share\hadoop\common\hadoop-common-3.2.4-tests.jar;C:\hadoop\share\hadoop\common\hadoop-common-3.2.4.jar;C:\hadoop\share\hadoop\common\hadoop-kms-3.2.4.jar;C:\hadoop\share\hadoop\common\hadoop-nfs-3.2.4.jar;C:\hadoop\share\hadoop\hdfs;C:\hadoop\share\hadoop\hdfs\lib\accessors-smart-2.4.7.jar;C:\hadoop\share\hadoop\hdfs\lib\animal-sniffer-annotations-1.17.jar;C:\hadoop\share\hadoop\hdfs\lib\asm-5.0.4.jar;C:\hadoop\share\hadoop\hdfs\lib\audience-annotations-0.5.0.jar;C:\hadoop\share\hadoop\hdfs\lib\avro-1.7.7.jar;C:\hadoop\share\hadoop\hdfs\lib\checker-qual-2.5.2.jar;C:\hadoop\share\hadoop\hdfs\lib\commons-beanutils-1.9.4.jar;C:\hadoop\share\hadoop\hdfs\lib\commons-cli-1.2.jar;C:\hadoop\share\hadoop\hdfs\lib\commons-codec-1.11.jar;C:\hadoop\share\hadoop\hdfs\lib\commons-collections-3.2.2.jar;C:\hadoop\share\hadoop\hdfs\lib\commons-compress-1.21.jar;C:\hadoop\share\hadoop\hdfs\lib\commons-configuration2-2.1.1.jar;C:\hadoop\share\hadoop\hdfs\lib\commons-daemon-1.0.13.jar;C:\hadoop\share\hadoop\hdfs\lib\commons-io-2.8.0.jar;C:\hadoop\share\hadoop\hdfs\lib\commons-lang3-3.7.jar;C:\hadoop\share\hadoop\hdfs\lib\commons-logging-1.1.3.jar;C:\hadoop\share\hadoop\hdfs\lib\commons-math3-3.1.1.jar;C:\hadoop\share\hadoop\hdfs\lib\commons-net-3.6.jar;C:\hadoop\share\hadoop\hdfs\lib\commons-text-1.4.jar;C:\hadoop\share\hadoop\hdfs\lib\curator-client-2.13.0.jar;C:\hadoop\share\hadoop\hdfs\lib\curator-framework-2.13.0.jar;C:\hadoop\share\hadoop\hdfs\lib\curator-recipes-2.13.0.jar;C:\hadoop\share\hadoop\hdfs\lib\dnsjava-2.1.7.jar;C:\hadoop\share\hadoop\hdfs\lib\error_prone_annotations-2.2.0.jar;C:\hadoop\share\hadoop\hdfs\lib\failureaccess-1.0.jar;C:\hadoop\share\hadoop\hdfs\lib\gson-2.9.0.jar;C:\hadoop\share\hadoop\hdfs\lib\guava-27.0-jre.jar;C:\hadoop\share\hadoop\hdfs\lib\hadoop-annotations-3.2.4.jar;C:\hadoop\share\hadoop\hdfs\lib\hadoop-auth-3.2.4.jar;C:\hadoop\share\hadoop\hdfs\lib\htrace-core4-4.1.0-incubating.jar;C:\hadoop\share\hadoop\hdfs\lib\httpclient-4.5.13.jar;C:\hadoop\share\hadoop\hdfs\lib\httpcore-4.4.13.jar;C:\hadoop\share\hadoop\hdfs\lib\j2objc-annotations-1.1.jar;C:\hadoop\share\hadoop\hdfs\lib\jackson-annotations-2.10.5.jar;C:\hadoop\share\hadoop\hdfs\lib\jackson-core-2.10.5.jar;C:\hadoop\share\hadoop\hdfs\lib\jackson-core-asl-1.9.13.jar;C:\hadoop\share\hadoop\hdfs\lib\jackson-databind-2.10.5.1.jar;C:\hadoop\share\hadoop\hdfs\lib\jackson-jaxrs-1.9.13.jar;C:\hadoop\share\hadoop\hdfs\lib\jackson-mapper-asl-1.9.13.jar;C:\hadoop\share\hadoop\hdfs\lib\jackson-xc-1.9.13.jar;C:\hadoop\share\hadoop\hdfs\lib\javax.activation-api-1.2.0.jar;C:\hadoop\share\hadoop\hdfs\lib\javax.servlet-api-3.1.0.jar;C:\hadoop\share\hadoop\hdfs\lib\jaxb-api-2.2.11.jar;C:\hadoop\share\hadoop\hdfs\lib\jaxb-impl-2.2.3-1.jar;C:\hadoop\share\hadoop\hdfs\lib\jcip-annotations-1.0-1.jar;C:\hadoop\share\hadoop\hdfs\lib\jersey-core-1.19.jar;C:\hadoop\share\hadoop\hdfs\lib\jersey-json-1.19.jar;C:\hadoop\share\hadoop\hdfs\lib\jersey-server-1.19.jar;C:\hadoop\share\hadoop\hdfs\lib\jersey-servlet-1.19.jar;C:\hadoop\share\hadoop\hdfs\lib\jettison-1.1.jar;C:\hadoop\share\hadoop\hdfs\lib\jetty-http-9.4.43.v20210629.jar;C:\hadoop\share\hadoop\hdfs\lib\jetty-io-9.4.43.v20210629.jar;C:\hadoop\share\hadoop\hdfs\lib\jetty-security-9.4.43.v20210629.jar;C:\hadoop\share\hadoop\hdfs\lib\jetty-server-9.4.43.v20210629.jar;C:\hadoop\share\hadoop\hdfs\lib\jetty-servlet-9.4.43.v20210629.jar;C:\hadoop\share\hadoop\hdfs\lib\jetty-util-9.4.43.v20210629.jar;C:\hadoop\share\hadoop\hdfs\lib\jetty-util-ajax-9.4.43.v20210629.jar;C:\hadoop\share\hadoop\hdfs\lib\jetty-webapp-9.4.43.v20210629.jar;C:\hadoop\share\hadoop\hdfs\lib\jetty-xml-9.4.43.v20210629.jar;C:\hadoop\share\hadoop\hdfs\lib\jsch-0.1.55.jar;C:\hadoop\share\hadoop\hdfs\lib\json-simple-1.1.1.jar;C:\hadoop\share\hadoop\hdfs\lib\json-smart-2.4.7.jar;C:\hadoop\share\hadoop\hdfs\lib\jsr305-3.0.2.jar;C:\hadoop\share\hadoop\hdfs\lib\jsr311-api-1.1.1.jar;C:\hadoop\share\hadoop\hdfs\lib\kerb-admin-1.0.1.jar;C:\hadoop\share\hadoop\hdfs\lib\kerb-client-1.0.1.jar;C:\hadoop\share\hadoop\hdfs\lib\kerb-common-1.0.1.jar;C:\hadoop\share\hadoop\hdfs\lib\kerb-core-1.0.1.jar;C:\hadoop\share\hadoop\hdfs\lib\kerb-crypto-1.0.1.jar;C:\hadoop\share\hadoop\hdfs\lib\kerb-identity-1.0.1.jar;C:\hadoop\share\hadoop\hdfs\lib\kerb-server-1.0.1.jar;C:\hadoop\share\hadoop\hdfs\lib\kerb-simplekdc-1.0.1.jar;C:\hadoop\share\hadoop\hdfs\lib\kerb-util-1.0.1.jar;C:\hadoop\share\hadoop\hdfs\lib\kerby-asn1-1.0.1.jar;C:\hadoop\share\hadoop\hdfs\lib\kerby-config-1.0.1.jar;C:\hadoop\share\hadoop\hdfs\lib\kerby-pkix-1.0.1.jar;C:\hadoop\share\hadoop\hdfs\lib\kerby-util-1.0.1.jar;C:\hadoop\share\hadoop\hdfs\lib\kerby-xdr-1.0.1.jar;C:\hadoop\share\hadoop\hdfs\lib\leveldbjni-all-1.8.jar;C:\hadoop\share\hadoop\hdfs\lib\listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar;C:\hadoop\share\hadoop\hdfs\lib\netty-3.10.6.Final.jar;C:\hadoop\share\hadoop\hdfs\lib\netty-all-4.1.68.Final.jar;C:\hadoop\share\hadoop\hdfs\lib\nimbus-jose-jwt-9.8.1.jar;C:\hadoop\share\hadoop\hdfs\lib\okhttp-2.7.5.jar;C:\hadoop\share\hadoop\hdfs\lib\okio-1.6.0.jar;C:\hadoop\share\hadoop\hdfs\lib\paranamer-2.3.jar;C:\hadoop\share\hadoop\hdfs\lib\protobuf-java-2.5.0.jar;C:\hadoop\share\hadoop\hdfs\lib\re2j-1.1.jar;C:\hadoop\share\hadoop\hdfs\lib\reload4j-1.2.18.3.jar;C:\hadoop\share\hadoop\hdfs\lib\snappy-java-1.0.5.jar;C:\hadoop\share\hadoop\hdfs\lib\spotbugs-annotations-3.1.9.jar;C:\hadoop\share\hadoop\hdfs\lib\stax2-api-4.2.1.jar;C:\hadoop\share\hadoop\hdfs\lib\token-provider-1.0.1.jar;C:\hadoop\share\hadoop\hdfs\lib\woodstox-core-5.3.0.jar;C:\hadoop\share\hadoop\hdfs\lib\zookeeper-3.4.14.jar;C:\hadoop\share\hadoop\hdfs\hadoop-hdfs-3.2.4-tests.jar;C:\hadoop\share\hadoop\hdfs\hadoop-hdfs-3.2.4.jar;C:\hadoop\share\hadoop\hdfs\hadoop-hdfs-client-3.2.4-tests.jar;C:\hadoop\share\hadoop\hdfs\hadoop-hdfs-client-3.2.4.jar;C:\hadoop\share\hadoop\hdfs\hadoop-hdfs-httpfs-3.2.4.jar;C:\hadoop\share\hadoop\hdfs\hadoop-hdfs-native-client-3.2.4-tests.jar;C:\hadoop\share\hadoop\hdfs\hadoop-hdfs-native-client-3.2.4.jar;C:\hadoop\share\hadoop\hdfs\hadoop-hdfs-nfs-3.2.4.jar;C:\hadoop\share\hadoop\hdfs\hadoop-hdfs-rbf-3.2.4-tests.jar;C:\hadoop\share\hadoop\hdfs\hadoop-hdfs-rbf-3.2.4.jar;C:\hadoop\share\hadoop\yarn;C:\hadoop\share\hadoop\yarn\lib\aopalliance-1.0.jar;C:\hadoop\share\hadoop\yarn\lib\bcpkix-jdk15on-1.60.jar;C:\hadoop\share\hadoop\yarn\lib\bcprov-jdk15on-1.60.jar;C:\hadoop\share\hadoop\yarn\lib\ehcache-3.3.1.jar;C:\hadoop\share\hadoop\yarn\lib\fst-2.50.jar;C:\hadoop\share\hadoop\yarn\lib\geronimo-jcache_1.0_spec-1.0-alpha-1.jar;C:\hadoop\share\hadoop\yarn\lib\guice-4.0.jar;C:\hadoop\share\hadoop\yarn\lib\guice-servlet-4.0.jar;C:\hadoop\share\hadoop\yarn\lib\HikariCP-java7-2.4.12.jar;C:\hadoop\share\hadoop\yarn\lib\jackson-jaxrs-base-2.10.5.jar;C:\hadoop\share\hadoop\yarn\lib\jackson-jaxrs-json-provider-2.10.5.jar;C:\hadoop\share\hadoop\yarn\lib\jackson-module-jaxb-annotations-2.10.5.jar;C:\hadoop\share\hadoop\yarn\lib\jakarta.activation-api-1.2.1.jar;C:\hadoop\share\hadoop\yarn\lib\jakarta.xml.bind-api-2.3.2.jar;C:\hadoop\share\hadoop\yarn\lib\java-util-1.9.0.jar;C:\hadoop\share\hadoop\yarn\lib\javax.inject-1.jar;C:\hadoop\share\hadoop\yarn\lib\jersey-client-1.19.jar;C:\hadoop\share\hadoop\yarn\lib\jersey-guice-1.19.jar;C:\hadoop\share\hadoop\yarn\lib\json-io-2.5.1.jar;C:\hadoop\share\hadoop\yarn\lib\metrics-core-3.2.4.jar;C:\hadoop\share\hadoop\yarn\lib\mssql-jdbc-6.2.1.jre7.jar;C:\hadoop\share\hadoop\yarn\lib\objenesis-1.0.jar;C:\hadoop\share\hadoop\yarn\lib\snakeyaml-1.26.jar;C:\hadoop\share\hadoop\yarn\lib\swagger-annotations-1.5.4.jar;C:\hadoop\share\hadoop\yarn\hadoop-yarn-api-3.2.4.jar;C:\hadoop\share\hadoop\yarn\hadoop-yarn-applications-distributedshell-3.2.4.jar;C:\hadoop\share\hadoop\yarn\hadoop-yarn-applications-unmanaged-am-launcher-3.2.4.jar;C:\hadoop\share\hadoop\yarn\hadoop-yarn-client-3.2.4.jar;C:\hadoop\share\hadoop\yarn\hadoop-yarn-common-3.2.4.jar;C:\hadoop\share\hadoop\yarn\hadoop-yarn-registry-3.2.4.jar;C:\hadoop\share\hadoop\yarn\hadoop-yarn-server-applicationhistoryservice-3.2.4.jar;C:\hadoop\share\hadoop\yarn\hadoop-yarn-server-common-3.2.4.jar;C:\hadoop\share\hadoop\yarn\hadoop-yarn-server-nodemanager-3.2.4.jar;C:\hadoop\share\hadoop\yarn\hadoop-yarn-server-resourcemanager-3.2.4.jar;C:\hadoop\share\hadoop\yarn\hadoop-yarn-server-router-3.2.4.jar;C:\hadoop\share\hadoop\yarn\hadoop-yarn-server-sharedcachemanager-3.2.4.jar;C:\hadoop\share\hadoop\yarn\hadoop-yarn-server-tests-3.2.4.jar;C:\hadoop\share\hadoop\yarn\hadoop-yarn-server-timeline-pluginstorage-3.2.4.jar;C:\hadoop\share\hadoop\yarn\hadoop-yarn-server-web-proxy-3.2.4.jar;C:\hadoop\share\hadoop\yarn\hadoop-yarn-services-api-3.2.4.jar;C:\hadoop\share\hadoop\yarn\hadoop-yarn-services-core-3.2.4.jar;C:\hadoop\share\hadoop\yarn\hadoop-yarn-submarine-3.2.4.jar;C:\hadoop\share\hadoop\mapreduce\lib\hamcrest-core-1.3.jar;C:\hadoop\share\hadoop\mapreduce\lib\junit-4.13.2.jar;C:\hadoop\share\hadoop\mapreduce\hadoop-mapreduce-client-app-3.2.4.jar;C:\hadoop\share\hadoop\mapreduce\hadoop-mapreduce-client-common-3.2.4.jar;C:\hadoop\share\hadoop\mapreduce\hadoop-mapreduce-client-core-3.2.4.jar;C:\hadoop\share\hadoop\mapreduce\hadoop-mapreduce-client-hs-3.2.4.jar;C:\hadoop\share\hadoop\mapreduce\hadoop-mapreduce-client-hs-plugins-3.2.4.jar;C:\hadoop\share\hadoop\mapreduce\hadoop-mapreduce-client-jobclient-3.2.4-tests.jar;C:\hadoop\share\hadoop\mapreduce\hadoop-mapreduce-client-jobclient-3.2.4.jar;C:\hadoop\share\hadoop\mapreduce\hadoop-mapreduce-client-nativetask-3.2.4.jar;C:\hadoop\share\hadoop\mapreduce\hadoop-mapreduce-client-shuffle-3.2.4.jar;C:\hadoop\share\hadoop\mapreduce\hadoop-mapreduce-client-uploader-3.2.4.jar;C:\hadoop\share\hadoop\mapreduce\hadoop-mapreduce-examples-3.2.4.jar
STARTUP_MSG:   build = Unknown -r 7e5d9983b388e372fe640f21f048f2f2ae6e9eba; compiled by 'ubuntu' on 2022-07-12T11:58Z
STARTUP_MSG:   java = 1.8.0_411
************************************************************/
2025-04-23 15:46:01,786 INFO namenode.NameNode: createNameNode [-format]
Formatting using clusterid: CID-44fe4c04-9235-4eff-b432-a409c3d8a86e
2025-04-23 15:46:02,302 INFO namenode.FSEditLog: Edit logging is async:true
2025-04-23 15:46:02,333 INFO namenode.FSNamesystem: KeyProvider: null
2025-04-23 15:46:02,333 INFO namenode.FSNamesystem: fsLock is fair: true
2025-04-23 15:46:02,333 INFO namenode.FSNamesystem: Detailed lock hold time metrics enabled: false
2025-04-23 15:46:02,333 INFO namenode.FSNamesystem: fsOwner             = Welcome (auth:SIMPLE)
2025-04-23 15:46:02,333 INFO namenode.FSNamesystem: supergroup          = supergroup
2025-04-23 15:46:02,333 INFO namenode.FSNamesystem: isPermissionEnabled = true
2025-04-23 15:46:02,333 INFO namenode.FSNamesystem: HA Enabled: false
2025-04-23 15:46:02,380 INFO common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2025-04-23 15:46:02,380 INFO blockmanagement.DatanodeManager: dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2025-04-23 15:46:02,380 INFO blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2025-04-23 15:46:02,396 INFO blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2025-04-23 15:46:02,396 INFO blockmanagement.BlockManager: The block deletion will start around 2025 Apr 23 15:46:02
2025-04-23 15:46:02,396 INFO util.GSet: Computing capacity for map BlocksMap
2025-04-23 15:46:02,396 INFO util.GSet: VM type       = 64-bit
2025-04-23 15:46:02,396 INFO util.GSet: 2.0% max memory 889 MB = 17.8 MB
2025-04-23 15:46:02,396 INFO util.GSet: capacity      = 2^21 = 2097152 entries
2025-04-23 15:46:02,396 INFO blockmanagement.BlockManager: Storage policy satisfier is disabled
2025-04-23 15:46:02,396 INFO blockmanagement.BlockManager: dfs.block.access.token.enable = false
2025-04-23 15:46:02,412 INFO blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2025-04-23 15:46:02,412 INFO blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.min.datanodes = 0
2025-04-23 15:46:02,412 INFO blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.extension = 30000
2025-04-23 15:46:02,412 INFO blockmanagement.BlockManager: defaultReplication         = 3
2025-04-23 15:46:02,412 INFO blockmanagement.BlockManager: maxReplication             = 512
2025-04-23 15:46:02,412 INFO blockmanagement.BlockManager: minReplication             = 1
2025-04-23 15:46:02,412 INFO blockmanagement.BlockManager: maxReplicationStreams      = 2
2025-04-23 15:46:02,412 INFO blockmanagement.BlockManager: redundancyRecheckInterval  = 3000ms
2025-04-23 15:46:02,412 INFO blockmanagement.BlockManager: encryptDataTransfer        = false
2025-04-23 15:46:02,412 INFO blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2025-04-23 15:46:02,427 INFO namenode.FSDirectory: GLOBAL serial map: bits=29 maxEntries=536870911
2025-04-23 15:46:02,427 INFO namenode.FSDirectory: USER serial map: bits=24 maxEntries=16777215
2025-04-23 15:46:02,427 INFO namenode.FSDirectory: GROUP serial map: bits=24 maxEntries=16777215
2025-04-23 15:46:02,427 INFO namenode.FSDirectory: XATTR serial map: bits=24 maxEntries=16777215
2025-04-23 15:46:02,443 INFO util.GSet: Computing capacity for map INodeMap
2025-04-23 15:46:02,443 INFO util.GSet: VM type       = 64-bit
2025-04-23 15:46:02,443 INFO util.GSet: 1.0% max memory 889 MB = 8.9 MB
2025-04-23 15:46:02,443 INFO util.GSet: capacity      = 2^20 = 1048576 entries
2025-04-23 15:46:02,458 INFO namenode.FSDirectory: ACLs enabled? false
2025-04-23 15:46:02,458 INFO namenode.FSDirectory: POSIX ACL inheritance enabled? true
2025-04-23 15:46:02,458 INFO namenode.FSDirectory: XAttrs enabled? true
2025-04-23 15:46:02,458 INFO namenode.NameNode: Caching file names occurring more than 10 times
2025-04-23 15:46:02,474 INFO snapshot.SnapshotManager: Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2025-04-23 15:46:02,474 INFO snapshot.SnapshotManager: SkipList is disabled
2025-04-23 15:46:02,474 INFO util.GSet: Computing capacity for map cachedBlocks
2025-04-23 15:46:02,474 INFO util.GSet: VM type       = 64-bit
2025-04-23 15:46:02,474 INFO util.GSet: 0.25% max memory 889 MB = 2.2 MB
2025-04-23 15:46:02,474 INFO util.GSet: capacity      = 2^18 = 262144 entries
2025-04-23 15:46:02,490 INFO metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2025-04-23 15:46:02,490 INFO metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2025-04-23 15:46:02,490 INFO metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2025-04-23 15:46:02,490 INFO namenode.FSNamesystem: Retry cache on namenode is enabled
2025-04-23 15:46:02,490 INFO namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2025-04-23 15:46:02,490 INFO util.GSet: Computing capacity for map NameNodeRetryCache
2025-04-23 15:46:02,490 INFO util.GSet: VM type       = 64-bit
2025-04-23 15:46:02,490 INFO util.GSet: 0.029999999329447746% max memory 889 MB = 273.1 KB
2025-04-23 15:46:02,490 INFO util.GSet: capacity      = 2^15 = 32768 entries
Re-format filesystem in Storage Directory root= \tmp\hadoop-Welcome\dfs\name; location= null ? (Y or N) Y
2025-04-23 15:46:04,914 INFO namenode.FSImage: Allocated new BlockPoolId: BP-1654839775-192.168.160.107-1745403364914
2025-04-23 15:46:04,914 INFO common.Storage: Will remove files: [\tmp\hadoop-Welcome\dfs\name\current\edits_inprogress_0000000000000000001, \tmp\hadoop-Welcome\dfs\name\current\fsimage_0000000000000000000, \tmp\hadoop-Welcome\dfs\name\current\fsimage_0000000000000000000.md5, \tmp\hadoop-Welcome\dfs\name\current\seen_txid, \tmp\hadoop-Welcome\dfs\name\current\VERSION]
2025-04-23 15:46:05,008 INFO common.Storage: Storage directory \tmp\hadoop-Welcome\dfs\name has been successfully formatted.
2025-04-23 15:46:05,023 INFO namenode.FSImageFormatProtobuf: Saving image file \tmp\hadoop-Welcome\dfs\name\current\fsimage.ckpt_0000000000000000000 using no compression
2025-04-23 15:46:05,101 INFO namenode.FSImageFormatProtobuf: Image file \tmp\hadoop-Welcome\dfs\name\current\fsimage.ckpt_0000000000000000000 of size 402 bytes saved in 0 seconds .
2025-04-23 15:46:05,101 INFO namenode.NNStorageRetentionManager: Going to retain 1 images with txid >= 0
2025-04-23 15:46:05,117 INFO namenode.FSNamesystem: Stopping services started for active state
2025-04-23 15:46:05,117 INFO namenode.FSNamesystem: Stopping services started for standby state
2025-04-23 15:46:05,133 INFO namenode.FSImage: FSImageSaver clean checkpoint: txid=0 when meet shutdown.
2025-04-23 15:46:05,133 INFO namenode.NameNode: SHUTDOWN_MSG:
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at DSBDA01/192.168.160.107
************************************************************/

C:\hadoop>start-all
This script is Deprecated. Instead use start-dfs.cmd and start-yarn.cmd
starting yarn daemons

C:\hadoop>jps
9392 NameNode
7076 NodeManager
2104 Jps
6376 DataNode
6796 ResourceManager

C:\hadoop>start-yarn
starting yarn daemons

C:\hadoop>cd sbin

C:\hadoop\sbin>start-all
This script is Deprecated. Instead use start-dfs.cmd and start-yarn.cmd
starting yarn daemons

C:\hadoop\sbin>jps
9392 NameNode
7076 NodeManager
9876 Jps
6376 DataNode
6796 ResourceManager

C:\hadoop\sbin>start-yarn
starting yarn daemons

C:\hadoop\sbin>jps
9392 NameNode
7076 NodeManager
3464 Jps
6376 DataNode
6796 ResourceManager

C:\hadoop\sbin>hadoop fs -mkdir /input4

C:\hadoop\sbin>hadoop fs -put c:\data.txt /input4

C:\hadoop\sbin>hadoop fs -ls /input4
Found 1 items
-rw-r--r--   3 Welcome supergroup        225 2025-04-23 15:49 /input4/data.txt

C:\hadoop\sbin>hadoop dfs -cat /input4/data.txt
DEPRECATED: Use of this script to execute hdfs command is deprecated.
Instead use the hdfs command for it.
Rakesh
Sakshi
Sakshi
Rakesh
Sakshi
Sakshi
Rakesh
Sakshi
Sakshi
Rakesh
Sakshi
Sakshi
Rakesh
Sakshi
Sakshi
Rakesh
Sakshi
Sakshi
Rakesh
Sakshi
Sakshi
Rakesh
Sakshi
Sakshi
Rakesh
Sakshi
Sakshi

C:\hadoop\sbin>hadoop jar C:\hadoop\share\hadoop\mapreduce\hadoop-mapreduce-examples-3.2.4.jar wordcount/input4 /out
Unknown program 'wordcount/input4' chosen.
Valid program names are:
  aggregatewordcount: An Aggregate based map/reduce program that counts the words in the input files.
  aggregatewordhist: An Aggregate based map/reduce program that computes the histogram of the words in the input files.
  bbp: A map/reduce program that uses Bailey-Borwein-Plouffe to compute exact digits of Pi.
  dbcount: An example job that count the pageview counts from a database.
  distbbp: A map/reduce program that uses a BBP-type formula to compute exact bits of Pi.
  grep: A map/reduce program that counts the matches of a regex in the input.
  join: A job that effects a join over sorted, equally partitioned datasets
  multifilewc: A job that counts words from several files.
  pentomino: A map/reduce tile laying program to find solutions to pentomino problems.
  pi: A map/reduce program that estimates Pi using a quasi-Monte Carlo method.
  randomtextwriter: A map/reduce program that writes 10GB of random textual data per node.
  randomwriter: A map/reduce program that writes 10GB of random data per node.
  secondarysort: An example defining a secondary sort to the reduce.
  sort: A map/reduce program that sorts the data written by the random writer.
  sudoku: A sudoku solver.
  teragen: Generate data for the terasort
  terasort: Run the terasort
  teravalidate: Checking results of terasort
  wordcount: A map/reduce program that counts the words in the input files.
  wordmean: A map/reduce program that counts the average length of the words in the input files.
  wordmedian: A map/reduce program that counts the median length of the words in the input files.
  wordstandarddeviation: A map/reduce program that counts the standard deviation of the length of the words in the input files.

C:\hadoop\sbin>hadoop fs -cat /out/*
cat: `/out/*': No such file or directory

C:\hadoop\sbin>hadoop jar C:\hadoop\share\hadoop\mapreduce\hadoop-mapreduce-examples-3.2.4.jar wordcount /input4 /out
2025-04-23 15:52:53,540 INFO client.RMProxy: Connecting to ResourceManager at /0.0.0.0:8032
2025-04-23 15:52:54,027 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/Welcome/.staging/job_1745403376518_0001
2025-04-23 15:52:54,230 INFO input.FileInputFormat: Total input files to process : 1
2025-04-23 15:52:54,355 INFO mapreduce.JobSubmitter: number of splits:1
2025-04-23 15:52:54,511 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1745403376518_0001
2025-04-23 15:52:54,511 INFO mapreduce.JobSubmitter: Executing with tokens: []
2025-04-23 15:52:54,651 INFO conf.Configuration: resource-types.xml not found
2025-04-23 15:52:54,651 INFO resource.ResourceUtils: Unable to find 'resource-types.xml'.
2025-04-23 15:52:55,045 INFO impl.YarnClientImpl: Submitted application application_1745403376518_0001
2025-04-23 15:52:55,107 INFO mapreduce.Job: The url to track the job: http://DSBDA01:8088/proxy/application_1745403376518_0001/
2025-04-23 15:52:55,107 INFO mapreduce.Job: Running job: job_1745403376518_0001
2025-04-23 15:53:02,209 INFO mapreduce.Job: Job job_1745403376518_0001 running in uber mode : false
2025-04-23 15:53:02,212 INFO mapreduce.Job:  map 0% reduce 0%
2025-04-23 15:53:07,309 INFO mapreduce.Job:  map 100% reduce 0%
2025-04-23 15:53:12,319 INFO mapreduce.Job:  map 100% reduce 100%
2025-04-23 15:53:12,334 INFO mapreduce.Job: Job job_1745403376518_0001 completed successfully
2025-04-23 15:53:12,397 INFO mapreduce.Job: Counters: 54
        File System Counters
                FILE: Number of bytes read=32
                FILE: Number of bytes written=478587
                FILE: Number of read operations=0
                FILE: Number of large read operations=0
                FILE: Number of write operations=0
                HDFS: Number of bytes read=327
                HDFS: Number of bytes written=19
                HDFS: Number of read operations=8
                HDFS: Number of large read operations=0
                HDFS: Number of write operations=2
                HDFS: Number of bytes read erasure-coded=0
        Job Counters
                Launched map tasks=1
                Launched reduce tasks=1
                Data-local map tasks=1
                Total time spent by all maps in occupied slots (ms)=2119
                Total time spent by all reduces in occupied slots (ms)=2254
                Total time spent by all map tasks (ms)=2119
                Total time spent by all reduce tasks (ms)=2254
                Total vcore-milliseconds taken by all map tasks=2119
                Total vcore-milliseconds taken by all reduce tasks=2254
                Total megabyte-milliseconds taken by all map tasks=2169856
                Total megabyte-milliseconds taken by all reduce tasks=2308096
        Map-Reduce Framework
                Map input records=27
                Map output records=27
                Map output bytes=297
                Map output materialized bytes=32
                Input split bytes=102
                Combine input records=27
                Combine output records=2
                Reduce input groups=2
                Reduce shuffle bytes=32
                Reduce input records=2
                Reduce output records=2
                Spilled Records=4
                Shuffled Maps =1
                Failed Shuffles=0
                Merged Map outputs=1
                GC time elapsed (ms)=53
                CPU time spent (ms)=841
                Physical memory (bytes) snapshot=533372928
                Virtual memory (bytes) snapshot=770363392
                Total committed heap usage (bytes)=386400256
                Peak Map Physical memory (bytes)=315953152
                Peak Map Virtual memory (bytes)=381865984
                Peak Reduce Physical memory (bytes)=217419776
                Peak Reduce Virtual memory (bytes)=388497408
        Shuffle Errors
                BAD_ID=0
                CONNECTION=0
                IO_ERROR=0
                WRONG_LENGTH=0
                WRONG_MAP=0
                WRONG_REDUCE=0
        File Input Format Counters
                Bytes Read=225
        File Output Format Counters
                Bytes Written=19

C:\hadoop\sbin>hadoop fs -cat /out/*
Rakesh  9
Sakshi  18

C:\hadoop\sbin>